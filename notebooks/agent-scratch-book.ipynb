{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Agent Scratch Book"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19e80eb3e1af4dd"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from aicraft.models import GPT, LLaMa, Qwen, DeepSeek, Gemma\n",
    "from aicraft.types import InferenceRequest\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:16:59.468330Z",
     "start_time": "2024-08-10T07:16:58.330561Z"
    }
   },
   "id": "7c0b86c74a21fa5e",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialise Models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a059b041dc28e56"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gemma2 = Gemma() # obliterated\n",
    "qwen2 = Qwen() # For faster generations\n",
    "llama3 = LLaMa() # More capable, but slower\n",
    "deepseek2 = DeepSeek() # Code generator\n",
    "gpt4o = GPT() # Fast, Very capable, but costly"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:02.452240Z",
     "start_time": "2024-08-10T07:16:59.823201Z"
    }
   },
   "id": "def5587ac23a24de",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "    Data model for SQL response\n",
      "    contentType: str one of [application/json, text/plain, text/markdown]\n",
      "    sql: str\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class SQLResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    Data model for SQL response\n",
    "    contentType: str one of [application/json, text/plain, text/markdown]\n",
    "    sql: str\n",
    "    \"\"\"\n",
    "    contentType: str\n",
    "    sql: str\n",
    "    \n",
    "logger.info(SQLResponse.__doc__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:02.456701Z",
     "start_time": "2024-08-10T07:17:02.453398Z"
    }
   },
   "id": "148ba2aa3de0962a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Instruction:\n",
    "You are postgres database developer who is instructed to write SQL queries to fetch data from the database. Your SQL is required to be efficient and not contain any syntax errors. Here are the DDLs for the database:\n",
    "\n",
    "DDL:\n",
    "create table behaviour.interest (\n",
    "  gender text, -- User gender: Male | Female | Non-Binary\n",
    "  age_range text, -- User age range: 13-17 | 18-24 | 25-34 | 35-44 | 45-54 | 55-64 |65+ \n",
    "  city_name text, -- User city\n",
    "  state_name text, -- User state\n",
    "  country_name text, -- User country\n",
    "  user_count integer, -- Number of users that endorsed\n",
    "  subject text, -- Product, service, or content endorsed\n",
    "  description text, -- Description of product, service, or content\n",
    "  link text, -- Link to product, service, or content\n",
    "  image_link text, -- Link to image of product, service, or content\n",
    "  tag_1 text, -- User provided category for product, service or content\n",
    "  tag_2 text,\n",
    "  tag_3 text,\n",
    "  tag_4 text,\n",
    "  tag_5 text,\n",
    "  tag_6 text,\n",
    "  tag_7 text,\n",
    "  tag_8 text,\n",
    "  tag_9 text, \n",
    "  tag_10 text\n",
    ");\n",
    "\n",
    "Respond back only with error free sql syntax only\n",
    "\"\"\"\n",
    "QUESTION = \"Respond back with SQL only: which age group have provided the highest number of endorsements across the entire dataset?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": QUESTION },\n",
    "]\n",
    "\n",
    "single_message = [{\"role\": \"user\", \"content\":messages[0][\"content\"] + messages[1][\"content\"] }]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:02.459614Z",
     "start_time": "2024-08-10T07:17:02.457302Z"
    }
   },
   "id": "96d76c10208d1457",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 ms, sys: 94.7 ms, total: 112 ms\n",
      "Wall time: 2.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "InferenceResponse(role='assistant', content=SQLResponse(contentType='application/json', sql='SELECT age_range, SUM(user_count) AS total_endorsements\\nFROM behaviour.interest\\nGROUP BY age_range\\nORDER BY total_endorsements DESC\\nLIMIT 1;'))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = gpt4o.generate(InferenceRequest(\n",
    "    messages=messages,\n",
    "    response_format=SQLResponse,\n",
    "))\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:04.505015Z",
     "start_time": "2024-08-10T07:17:02.460764Z"
    }
   },
   "id": "c8ee17a0d3cc1f86",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char ::= [^\"\\] | [\\] char_1 \n",
      "char_1 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "contentType-kv ::= [\"] [c] [o] [n] [t] [e] [n] [t] [T] [y] [p] [e] [\"] space [:] space string \n",
      "space ::= space_7 \n",
      "string ::= [\"] string_8 [\"] space \n",
      "root ::= [{] space contentType-kv [,] space sql-kv [}] space \n",
      "sql-kv ::= [\"] [s] [q] [l] [\"] space [:] space string \n",
      "space_7 ::= [ ] | \n",
      "string_8 ::= char string_8 | \n",
      "CPU times: user 510 ms, sys: 662 ms, total: 1.17 s\n",
      "Wall time: 9.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "InferenceResponse(role='assistant', content=SQLResponse(contentType='text', sql='SELECT age_range, SUM(user_count) AS total_endorsements FROM behaviour.interest GROUP BY age_range ORDER BY total_endorsements DESC LIMIT 1'))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = deepseek2.generate(InferenceRequest(\n",
    "    messages=messages,\n",
    "    response_format=SQLResponse,\n",
    "))\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:14.227111Z",
     "start_time": "2024-08-10T07:17:04.506484Z"
    }
   },
   "id": "38a0a9eacd70abf2",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char ::= [^\"\\] | [\\] char_1 \n",
      "char_1 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "contentType-kv ::= [\"] [c] [o] [n] [t] [e] [n] [t] [T] [y] [p] [e] [\"] space [:] space string \n",
      "space ::= space_7 \n",
      "string ::= [\"] string_8 [\"] space \n",
      "root ::= [{] space contentType-kv [,] space sql-kv [}] space \n",
      "sql-kv ::= [\"] [s] [q] [l] [\"] space [:] space string \n",
      "space_7 ::= [ ] | \n",
      "string_8 ::= char string_8 | \n",
      "CPU times: user 345 ms, sys: 465 ms, total: 809 ms\n",
      "Wall time: 2.69 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "InferenceResponse(role='assistant', content=SQLResponse(contentType='text/plain', sql='SELECT age_range, user_count FROM behaviour.interest ORDER BY user_count DESC LIMIT 1;'))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = llama3.generate(InferenceRequest(\n",
    "    messages=messages,\n",
    "    response_format=SQLResponse,\n",
    "))\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:16.915926Z",
     "start_time": "2024-08-10T07:17:14.227904Z"
    }
   },
   "id": "3938af5301ee0d10",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char ::= [^\"\\] | [\\] char_1 \n",
      "char_1 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "contentType-kv ::= [\"] [c] [o] [n] [t] [e] [n] [t] [T] [y] [p] [e] [\"] space [:] space string \n",
      "space ::= space_7 \n",
      "string ::= [\"] string_8 [\"] space \n",
      "root ::= [{] space contentType-kv [,] space sql-kv [}] space \n",
      "sql-kv ::= [\"] [s] [q] [l] [\"] space [:] space string \n",
      "space_7 ::= [ ] | \n",
      "string_8 ::= char string_8 | \n",
      "CPU times: user 511 ms, sys: 305 ms, total: 817 ms\n",
      "Wall time: 1.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "InferenceResponse(role='assistant', content=SQLResponse(contentType='sql', sql='SELECT gender, age_range, MAX(user_count) FROM behavior.interest GROUP BY gender, age_range ORDER BY MAX(user_count) DESC LIMIT 1'))"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = qwen2.generate(InferenceRequest(\n",
    "    messages=messages,\n",
    "    response_format=SQLResponse,\n",
    "))\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:18.370845Z",
     "start_time": "2024-08-10T07:17:16.917084Z"
    }
   },
   "id": "ad180df56a932d61",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char ::= [^\"\\] | [\\] char_1 \n",
      "char_1 ::= [\"\\/bfnrt] | [u] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] \n",
      "contentType-kv ::= [\"] [c] [o] [n] [t] [e] [n] [t] [T] [y] [p] [e] [\"] space [:] space string \n",
      "space ::= space_7 \n",
      "string ::= [\"] string_8 [\"] space \n",
      "root ::= [{] space contentType-kv [,] space sql-kv [}] space \n",
      "sql-kv ::= [\"] [s] [q] [l] [\"] space [:] space string \n",
      "space_7 ::= [ ] | \n",
      "string_8 ::= char string_8 | \n",
      "CPU times: user 871 ms, sys: 538 ms, total: 1.41 s\n",
      "Wall time: 2.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "InferenceResponse(role='assistant', content=SQLResponse(contentType='text/sql', sql='SELECT age_range, COUNT(*) AS endorsement_count FROM behaviour.interest GROUP BY age_range ORDER BY endorsement_count DESC LIMIT 1'))"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "response = gemma2.generate(InferenceRequest(\n",
    "    messages=messages,\n",
    "    response_format=SQLResponse,\n",
    "))\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-10T07:17:20.876538Z",
     "start_time": "2024-08-10T07:17:18.371552Z"
    }
   },
   "id": "b79692d7c810e4a8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c26d1d27311f4df2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
