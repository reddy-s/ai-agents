{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LoRA Implementation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c81bd009e3bbc20e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:51.905313Z",
     "start_time": "2024-06-30T21:19:50.732560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Using MPS\n"
     ]
    },
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "random.seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(\"Using GPU\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    logger.info(\"Using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    logger.info(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helpers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1104402448fa58c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_token(ins: torch.Tensor, model: torch.nn.Module, detokenizer: list[str]) -> list[str]:\n",
    "    with torch.no_grad():\n",
    "        _output = model(ins)\n",
    "    _next_token_ids = _output[:, -1, :].argmax(dim=1)\n",
    "    return [detokenizer[tid] for tid in _next_token_ids]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:52.893447Z",
     "start_time": "2024-06-30T21:19:52.891496Z"
    }
   },
   "id": "ca335d957b327e5",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating a Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1255ee8bb374d54"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class FakeModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embedding_size)\n",
    "        self.hidden = torch.nn.Linear(embedding_size, 1024)\n",
    "        self.head = torch.nn.Linear(1024, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x.long())\n",
    "        x = self.hidden(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:20:46.711233Z",
     "start_time": "2024-06-30T21:20:46.704542Z"
    }
   },
   "id": "3e0053154296efc1",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "_x = torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]])\n",
    "vocab = [\n",
    "    \"red\",\n",
    "    \"orange\",\n",
    "    \"yellow\",\n",
    "    \"green\",\n",
    "    \"blue\",\n",
    "    \"indigo\",\n",
    "    \"violet\",\n",
    "    \"magenta\",\n",
    "    \"marigold\",\n",
    "    \"chartreuse\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:55.489100Z",
     "start_time": "2024-06-30T21:19:55.486218Z"
    }
   },
   "id": "d3e4be8ad42db64c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "FakeModel(\n  (embedding): Embedding(10, 1024)\n  (hidden): Linear(in_features=1024, out_features=1024, bias=True)\n  (head): Linear(in_features=1024, out_features=10, bias=True)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_model = FakeModel(vocab_size=len(vocab), embedding_size=1024)\n",
    "fake_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:56.092496Z",
     "start_time": "2024-06-30T21:19:56.085533Z"
    }
   },
   "id": "3ee9e49319185b33",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['yellow']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_generated_tokens = generate_token(ins=_x, model=fake_model, detokenizer=vocab)\n",
    "_generated_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:56.694625Z",
     "start_time": "2024-06-30T21:19:56.690911Z"
    }
   },
   "id": "9b9977fb1378e99d",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing LoRA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c30785c4a55c17d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 1024])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(1, 8, 1024)\n",
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:58.507020Z",
     "start_time": "2024-06-30T21:19:58.504344Z"
    }
   },
   "id": "8e1a686fdcf4cec",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|A+B| / |W|: 0.00390625\n"
     ]
    }
   ],
   "source": [
    "W = fake_model.hidden.weight\n",
    "\n",
    "lora_a = torch.randn(1024, 2)\n",
    "lora_b = torch.randn(2, 1024)\n",
    "\n",
    "lora_numel = lora_a.numel() + lora_b.numel()\n",
    "base_numel = W.numel()\n",
    "print(\"|A+B| / |W|:\", lora_numel / base_numel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:59.041657Z",
     "start_time": "2024-06-30T21:19:59.038066Z"
    }
   },
   "id": "7b5ce127b1b88df2",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 1024])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the output of X @ W (the original linear layer)\n",
    "base_output = fake_model.hidden(X)\n",
    "\n",
    "# compute the output of X @ A @ B (the added lora adapter)\n",
    "lora_output = X @ lora_a @ lora_b\n",
    "\n",
    "# sum them together\n",
    "total_output = base_output + lora_output\n",
    "\n",
    "# output should have the same shape as the original output:\n",
    "# (batch_size, sequence_length, hidden_size)\n",
    "total_output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:19:59.590739Z",
     "start_time": "2024-06-30T21:19:59.587177Z"
    }
   },
   "id": "afea60eac6182c46",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LoraLayer(torch.nn.Module):\n",
    "    def __init__(self, base_layer, r):\n",
    "        super().__init__()\n",
    "        self.base_layer = base_layer\n",
    "        \n",
    "        d_in, d_out = self.base_layer.weight.shape\n",
    "        self.lora_a = torch.randn(d_in, r)\n",
    "        self.lora_b = torch.randn(r, d_out) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        y1 = self.base_layer(x)\n",
    "        y2 = x @ self.lora_a @ self.lora_b\n",
    "        return y1 + y2\n",
    "    \n",
    "    def during_inference(self, x):\n",
    "        return x @ self.lora_a @ self.lora_b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:20:00.347167Z",
     "start_time": "2024-06-30T21:20:00.343575Z"
    }
   },
   "id": "9644296af709cb0e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 8, 1024])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap the linear layer of our toy model, use rank 2\n",
    "lora_layer = LoraLayer(fake_model.hidden, 2)\n",
    "lora_layer(X).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:20:01.199214Z",
     "start_time": "2024-06-30T21:20:01.195646Z"
    }
   },
   "id": "652eb4454b650cda",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "FakeModel(\n  (embedding): Embedding(10, 1024)\n  (hidden): LoraLayer(\n    (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n  )\n  (head): Linear(in_features=1024, out_features=10, bias=True)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_model.hidden = lora_layer\n",
    "fake_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:20:01.777244Z",
     "start_time": "2024-06-30T21:20:01.774371Z"
    }
   },
   "id": "70de68a71c51e397",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['red']"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tokens = generate_token(ins=torch.LongTensor([[0, 1, 2, 3, 4, 5, 6, 7]]), model=fake_model, detokenizer=vocab)\n",
    "next_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-30T21:21:44.051190Z",
     "start_time": "2024-06-30T21:21:37.473064Z"
    }
   },
   "id": "39398f9d4afe27f",
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
